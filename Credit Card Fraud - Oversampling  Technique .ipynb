{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score,roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pandas_ml import ConfusionMatrix\n",
    "creditcard = pd.read_csv('xxxxx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prior to running the models, time and amount columns will be standardized since columns from V1 to V28 have undergone PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(np.array(creditcard['Amount']).reshape(-1,1))\n",
    "scaled_amount = scaler.transform(np.array(creditcard['Amount']).reshape(-1,1))\n",
    "scaler1 = StandardScaler().fit(np.array(creditcard['Time']).reshape(-1,1))\n",
    "scaled_time = scaler1.transform(np.array(creditcard['Time']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a 2nd dataframe with scaled amount and scaled time as columns. Will drop the original \"time\" and \"amount\" column\n",
    "df = pd.DataFrame(scaled_amount,columns =['scaled_amount'])\n",
    "df2 = pd.DataFrame(scaled_time,columns =['scaled_time'])\n",
    "credit_card_ss = pd.concat([creditcard,df, df2], axis=1)\n",
    "cols_to_drop =['Time','Amount']\n",
    "credit_card_ss = credit_card_ss[credit_card_ss.columns.drop(cols_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_credit_card_ss = credit_card_ss.drop('Class', axis=1)\n",
    "y_credit_card_ss = credit_card_ss['Class']\n",
    "X_credit_card_ss_train, X_credit_card_ss_test, y_credit_card_ss_train, y_credit_card_ss_test = train_test_split(X_credit_card_ss, y_credit_card_ss, test_size=0.3, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    10000\n",
      "0    10000\n",
      "Name: Class, dtype: int64\n",
      "Dimension of creditcard_original_leftover:(274405, 31)\n",
      "Dimension of creditcard_oversampled: (20000, 31)\n",
      "Dimension of creditcard: (284807, 31)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample \n",
    "\n",
    "# Separate majority and minority classes\n",
    "creditcard_nonfraud = credit_card_ss[credit_card_ss.Class==0]\n",
    "creditcard_fraud = credit_card_ss[credit_card_ss.Class==1]\n",
    "#In order to build this oversample dataset, I will take 300 fraud cases of original dataset and store them in a dataframe, then replicate those values to 10000. \n",
    "#Will take 10000 non fraud cases from original datgaset without replacement and store in a different dataset.\n",
    "#Will combine both datasets to form the oversampled dataset on which the models will train. The reason for taking only 300\n",
    "#fraud cases instead of all cases of fraud was to leave behind some of them so model can be validated. The model can only be \n",
    "#tested on data that it has not seen as a validation step.\n",
    "\n",
    "creditcard_undersampled = resample(credit_card_ss[credit_card_ss.Class==1], \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=300,     # represent around 61% of fraudulent cases\n",
    "                                 random_state=75) # reproducible results\n",
    "\n",
    "creditcard_oversampled_fraud = resample(creditcard_undersampled, \n",
    "                                 replace=True,    # sample with replacement the fraud cases \n",
    "                                 n_samples=10000,     # replicating the minority cases to 5000\n",
    "                                 random_state=75) # reproducible results\n",
    "\n",
    "\n",
    "# Take equal number of majority classes\n",
    "creditcard_nonfraud_undersampled = resample(credit_card_ss[credit_card_ss.Class==0], \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=10000,     # to match minority class\n",
    "                                 random_state=70) # reproducible results\n",
    "\n",
    "# Combine upsampled minority class with downsampled majority class\n",
    "creditcard_oversampled = pd.concat([creditcard_nonfraud_undersampled, creditcard_oversampled_fraud])\n",
    "\n",
    "# Display new class counts\n",
    "print(creditcard_oversampled.Class.value_counts())\n",
    "\n",
    "\n",
    "#Creating new dataframe which does not contain the data that is present in creditcard_undersampled dataset\n",
    "creditcard_original_leftover = credit_card_ss.loc[~credit_card_ss.set_index(list(credit_card_ss.columns)).index.isin(creditcard_oversampled.set_index(list(creditcard_oversampled.columns)).index)]\n",
    "#Checking shape of all datasets\n",
    "print ('Dimension of creditcard_original_leftover:'+str(creditcard_original_leftover.shape))\n",
    "print('Dimension of creditcard_oversampled:',str(creditcard_oversampled.shape))\n",
    "print('Dimension of creditcard:',str(credit_card_ss.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    274222\n",
       "1       183\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(creditcard_original_leftover['Class'].values, sort=False) #Checking the value counts of column class in the original \n",
    "#dataset that does not contain the data used for building the oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting oversampled dataset \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_over = creditcard_oversampled.drop('Class', axis=1)\n",
    "y_over = creditcard_oversampled['Class']\n",
    "X_over_train, X_over_test, y_over_train, y_over_test = train_test_split(X_over, y_over, test_size=0.3, random_state=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use logistic regression on undersampeld dataset and get the scores. \n",
    "#Will use gridsearch as well to see which hyperparameters give the best recall and f1 scores. \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_candidates = {'penalty':['l2','l1'],'C': [0.001,1, 10, 100, 1000]}\n",
    "\n",
    "cv_range=[10,20]\n",
    "for i in cv_range:\n",
    "    lr_over = GridSearchCV(estimator=LogisticRegression(random_state=90), param_grid=parameter_candidates, n_jobs=-1, cv=i)\n",
    "\n",
    "#Training set \n",
    "    lr_over.fit(X_over_train,y_over_train)\n",
    "\n",
    "#Prediction on training set - undersampled \n",
    "    pred_y_lr_over = lr_over.predict(X_over_test)\n",
    "\n",
    "#Getting accuracy scores on the undersampled dataset \n",
    "#Accuracy and Recall scores. \n",
    "print ('Accuracy score of logistic regression classifier on test set:{:.3f}'.format(accuracy_score(y_over_test,pred_y_lr_over)))\n",
    "print ('Recall score of logistic regression classifier on test set:{:.3f}'.format(recall_score(y_over_test,pred_y_lr_over)))\n",
    "print ('F1 score of logistic regression classifier on test set:{:.3f}'.format(f1_score(y_over_test,pred_y_lr_over)))\n",
    "print()\n",
    "cm_lr_over = confusion_matrix(y_over_test,pred_y_lr_over)\n",
    "print('Confusion matrix with logistic regression classifier with oversampled test set:\\n%s' % cm_lr_over)\n",
    "print()\n",
    "print('Best C for logistic regression:',lr_over.best_estimator_.C) \n",
    "print('Best penalty:',lr_over.best_estimator_.penalty)\n",
    "print('The best paramaters for the logistic regression classifier according to GridSearch and CV = %r:'% (i),lr_over.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using decision tree classifier on undersampled training set\n",
    "#Will use gridsearch as well to see which hyperparameters give the best recall and f1 scores. \n",
    "\n",
    "parameter_candidates = {'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\n",
    "cv_range=[5,10,20]\n",
    "for i in cv_range:\n",
    "    dt_over = GridSearchCV(estimator=DecisionTreeClassifier(random_state=75), param_grid=parameter_candidates, n_jobs=-1, cv=i)\n",
    "\n",
    "#Training set \n",
    "    dt_over.fit(X_over_train,y_over_train)\n",
    "\n",
    "#Prediction on training set - undersampled \n",
    "    pred_y_dt_over = dt_over.predict(X_over_test)\n",
    "\n",
    "#Getting accuracy scores on the undersampled dataset \n",
    "#Accuracy and Recall scores. \n",
    "print ('Accuracy score of decision tree classifier on test set:{:.3f}'.format(accuracy_score(y_over_test,pred_y_dt_over)))\n",
    "print ('Recall score of decision tree classifier on test set:{:.3f}'.format(recall_score(y_over_test,pred_y_dt_over)))\n",
    "print ('F1 score of decision tree classifier on test set:{:.3f}'.format(f1_score(y_over_test,pred_y_dt_over)))\n",
    "print()\n",
    "cm_dt_over = confusion_matrix(y_over_test,pred_y_dt_over)\n",
    "print('Confusion matrix with decision tree classifier with on oversampled test set:\\n%s' % cm_dt_over)\n",
    "print()\n",
    "print('The best paramaters for the decision tree classifier according to GridSearch and CV = %r:'% (i),dt_over.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "model = lr.fit(X_over_train, y_over_train)\n",
    "y_pred = model.predict(X_over_test)\n",
    "print ('Accuracy score of logistic regression classifier on test set:{:.3f}'.format(accuracy_score(y_over_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using SVM classifier \n",
    "#Will use gridsearch as well to see which hyperparameters give the best recall and f1 scores. \n",
    "from sklearn import svm\n",
    "parameter_candidates = {'C': [0.001, 0.01,10, 100, 1000], \n",
    "              'kernel': ['rbf', 'linear','poly'],\n",
    "              'gamma': [0.001, 0.01, 10, 100, 1000] \n",
    "             }\n",
    "cv_range=[10,20]\n",
    "for i in cv_range:\n",
    "    svc_under = GridSearchCV(estimator=svm.SVC(random_state=60), param_grid=parameter_candidates, n_jobs=-1, cv=i)\n",
    "\n",
    "#Training set \n",
    "    svc_under.fit(X_under_train,y_under_train)\n",
    "\n",
    "#Prediction on training set - undersampled \n",
    "    pred_y_svc_under = svc_under.predict(X_under_test)\n",
    "\n",
    "#Getting accuracy scores on the undersampled dataset \n",
    "#Accuracy and Recall scores. \n",
    "print ('Accuracy score of SVM classifier on test set:{:.3f}'.format(accuracy_score(y_under_test,pred_y_svc_under)))\n",
    "print ('Recall score of SVM classifier on test set:{:.3f}'.format(recall_score(y_under_test,pred_y_svc_under)))\n",
    "print ('F1 score of SVM classifier on test set:{:.3f}'.format(f1_score(y_under_test,pred_y_svc_under)))\n",
    "print()\n",
    "cm_svc_under = confusion_matrix(y_under_test,pred_y_svc_under)\n",
    "print('Confusion matrix with SVM classifier with on undersampled test set:\\n%s' % cm_svc_under)\n",
    "print()\n",
    "print('The best paramaters for the SVM classifier according to GridSearch and CV = %r:'% (i),svc_under.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
